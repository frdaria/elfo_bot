{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxmD6nMEyirx"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade huggingface_hub\n",
        "!pip install --upgrade fireworks-ai\n",
        "#!pip install telebot\n",
        "!pip install python-telegram-bot --upgrade\n",
        "!pip install pyTelegramBotAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZhkuuLC02Tvq"
      },
      "outputs": [],
      "source": [
        "import telebot\n",
        "import pandas as pd\n",
        "import random\n",
        "from huggingface_hub import InferenceClient\n",
        "import logging\n",
        "from collections import deque\n",
        "from telebot import types\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/frdaria/elfo_bot.git"
      ],
      "metadata": {
        "id": "k6THklsAvq6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('elfo_bot/prompts_fandom.csv', on_bad_lines='skip')\n",
        "chunks = pd.read_csv('elfo_bot/chunks_kinopoisk.csv', on_bad_lines='skip')\n",
        "vectors = np.load('/content/elfo_bot/bg3_m3_kinopoisk_chunks.npy')"
      ],
      "metadata": {
        "id": "4x3awbpZtwiu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_gemma = InferenceClient(\n",
        "    provider=\"hf-inference\",\n",
        "    api_key=api_key,)\n",
        "# client_picture = InferenceClient(\n",
        "#     provider=\"fal-ai\",\n",
        "#     api_key=api_key,)\n",
        "# client_mistral = InferenceClient(\n",
        "#     provider=\"fireworks-ai\",\n",
        "#     api_key=api_key,\n",
        "# )"
      ],
      "metadata": {
        "id": "qGElt3Yx4N1V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciwye52_pcUS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-KzYOIEpcWr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PMkpo3xDsccZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zNOvVa5uIAL_"
      },
      "outputs": [],
      "source": [
        "prompt_system_dialogue = '''Ты - волшебный эльф по имени Элфо! Ты - добрый писатель, ты пишешь приличный, дружелюбный и захватывающий контент на русском языке. Ты используешь много эмодзи! Твои тексты просты для чтения, полны диалогов, юмора и шуток! Твоя специализация - фанфики! Ты могу писать тексты в стиле фэнтези про знаменитостей и популярных персонажей книг и сериалов. Ты всегда включаешь рандомного популярного персонажа в сюжет. Когда пользователь дает тебе тему истории, ты начинаешь со слов \"Однажды...\" и заканчиваешь словами \"Продолжим читать?\". Если пользователь задает тебе вопрос, не связанный с темой истории, ты отвечаешь: 'Я просто Элфо! Какую историю ты хочешь почитать?'''\n",
        "\n",
        "# def dialogue_model(user_question: str, context: list) -> str:\n",
        "#     messages = [\n",
        "#                 {\n",
        "#                   \"role\": \"system\",\n",
        "#                   \"content\": prompt_system_dialogue\n",
        "#                 },\n",
        "#                ]\n",
        "#     if context:\n",
        "#          messages.extend(context)\n",
        "\n",
        "#     question = [{'role':'user',\n",
        "#                  'content': user_question}]\n",
        "#     messages.extend(question)\n",
        "#     completion = client_mistral.chat.completions.create(\n",
        "#       model=\"mistralai/Mistral-Small-24B-Instruct-2501\",\n",
        "# \t    messages=messages,\n",
        "#   \t  max_tokens=200,\n",
        "#     )\n",
        "#     return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "def update_context(context, user_m, answer):\n",
        "    new_data = [{'role': 'user', 'content': user_m},\n",
        "                {'role': 'system', 'content': answer}]\n",
        "    context.extend(new_data)\n",
        "    return context\n",
        "\n",
        "def get_random_prompt():\n",
        "    prompts = [\n",
        "        \"Жил-был дракон, который любил чай...\",\n",
        "        \"Однажды в далёкой галактике...\",\n",
        "        \"В маленькой деревне жил волшебник, который боялся магии...\"\n",
        "    ]\n",
        "    return random.choice(prompts)\n",
        "\n",
        "# def get_fandom_prompt(fandom):\n",
        "#     prompts = {\n",
        "#         \"🪄 Гарри Поттер\": \"Напиши историю о Гарри Поттере, который обнаружил новое заклинание...\",\n",
        "#         \"🧙 Властелин Колец\": \"Напиши историю о Фродо, который нашёл новое кольцо...\",\n",
        "#         \"⭐ Звёздные Войны\": \"Напиши историю о Люке Скайуокере, который встретил нового дроида...\"\n",
        "#     }\n",
        "#     return prompts.get(fandom, \"Фандом не найден.\")\n",
        "\n",
        "def get_fandom_prompt(df, fandom):\n",
        "    if fandom in df.columns:\n",
        "        prompts = df[fandom].dropna().tolist()\n",
        "        if prompts:\n",
        "            return random.choice(prompts)\n",
        "        else:\n",
        "            return \"Для этого фандома нет промптов.\"\n",
        "    else:\n",
        "        return \"Фандом не найден.\"\n",
        "\n",
        "\n",
        "def process_dialogue_step(user_message, context):\n",
        "        try:\n",
        "            answer = gemma_generate(user_message, list(context))\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка в dialogue_model: {e}\")\n",
        "            return None, None\n",
        "        if not answer:\n",
        "            logging.error(\"Пустой ответ от dialogue_model\")\n",
        "            return None, None\n",
        "        context = update_context(context, user_message, answer)\n",
        "        logging.info(f\"Updated context: {context}\")\n",
        "        return answer, context\n",
        "\n",
        "#sys_prompt_gemma = \"\"\"Ты волшебный Эльф, который пишет волшебные фанфики на русском языке. Твоя задача: 1) по заданному контексту написать историю. 2) Написать промпт для иллюстрации к этой истории. Используй шаблон: 'История:...Иллюстрация:...'Всегда следуй этому шаблону!!!\"\"\"\n",
        "\n",
        "def gemma_generate(user_question: str, context: list) -> str:\n",
        "    messages=[{\n",
        "                \"role\": \"system\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": prompt_system_dialogue}]\n",
        "              }]\n",
        "    if context:\n",
        "         messages.extend(context)\n",
        "\n",
        "    question = [{\"role\":\"user\",\n",
        "                 \"content\": user_question}]\n",
        "    messages.extend(question)\n",
        "\n",
        "    completion = client_gemma.chat.completions.create(\n",
        "                model=\"google/gemma-3-27b-it\",\n",
        "                max_tokens=200,\n",
        "                messages = messages)\n",
        "\n",
        "    gemma_answer = completion.choices[0].message.content.replace('\\n\\n', '').replace('##', '')\n",
        "    return gemma_answer\n",
        "\n",
        "def gemma_create_prompt(story) -> str:\n",
        "    messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": f'Read the text and create a SIMPLE and SHORT prompt to illustrate the plot of the story. The prompt must be in English. Do not give any comments, your ouput must consist of the promplt only!!! Story: {story}'}]\n",
        "              }]\n",
        "    completion = client_gemma.chat.completions.create(\n",
        "                model=\"google/gemma-3-27b-it\",\n",
        "                max_tokens=50,\n",
        "                messages = messages)\n",
        "\n",
        "    description = completion.choices[0].message.content.replace('\\n\\n', '').replace('##', '')\n",
        "    return description\n",
        "\n",
        "def picture_generate(picture_prompt):\n",
        "    # output is a PIL.Image object\n",
        "    image = client_picture.text_to_image(f'mystical style inspired by old fairy tales books, flat design. {picture_prompt}',\n",
        "    model=\"stabilityai/stable-diffusion-3.5-large\",)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = gemma_create_prompt('''Однажды... в далёом королевстве Вальдемар, где магические арканы и древние заклятья плелись в ткани повседневной жизни, в тюрьму \"Стальной Зверь\" попал маг по имени Эйдан. Его обвинили в utilisationе запрещённой магии, и теперь он был заключён в пыточные казематы этой неприступной крепости. Но Эйдан не был бы магом, если бы не знал, как выбраться из любой ситуации! 🔥🏰✨\n",
        "\n",
        "В ночь, когда луна скрылась за облаками, Эйдан начал свой план побега. Он использовал свои магические знания, чтобы сотворить мощное заклятие, которое открыло тяжелые двери его камеры. Через узкие окно он выбрался на наружную стену, где встретил неожиданного союзника -\n",
        "Продолжать?''')\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ef7GLbpPzaxs",
        "outputId": "f14ca0f9-bbdd-46f4-ecb1-1d877fdc383f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A mage imprisoned in a fortress must escape using magic.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NPxLCjPzprcb"
      },
      "outputs": [],
      "source": [
        "# Ограничиваем контекст последними n сообщениями\n",
        "MAX_CONTEXT_LENGTH = 7\n",
        "context_q = deque(maxlen=MAX_CONTEXT_LENGTH)\n",
        "dialog_check = 0\n",
        "\n",
        "\n",
        "# @bot.message_handler(commands=[\"очистить\"])\n",
        "# def clear_context(message):\n",
        "#     global context_q\n",
        "#     context_q.clear()  # Очищаем контекст\n",
        "#     bot.reply_to(message, \"Контекст очищен. Начнём с чистого листа!\")\n",
        "\n",
        "fandoms = [\"🌹💌 Евгений Онегин\", \"🧙✨ Властелин Колец\", \"👑⚔️ Игра престолов\", \"🔥🐲 Dragon Age\", \"🦹🏻❤️ Алые сердца Корё\"]\n",
        "\n",
        "# def create_picture_keyboard():\n",
        "#     keyboard = [\n",
        "#         [types.KeyboardButton(\"Изобразить\")]\n",
        "#     ]\n",
        "#     return types.ReplyKeyboardMarkup(keyboard, resize_keyboard=True)\n",
        "\n",
        "# def create_picture_keyboard():\n",
        "#     keyboard = [\n",
        "#         [types.KeyboardButton(\"Изобразить\")]\n",
        "#     ]\n",
        "#     return types.ReplyKeyboardMarkup(keyboard)\n",
        "\n",
        "def create_picture_keyboard():\n",
        "    keyboard = types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)\n",
        "    button_fandom = types.KeyboardButton(\"Изобразить\")\n",
        "    keyboard.add(button_fandom)\n",
        "    return keyboard\n",
        "\n",
        "# Создаем клавиатуру\n",
        "def create_keyboard():\n",
        "    keyboard = types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)\n",
        "    button_fandom = types.KeyboardButton(\"📚 Выбрать фандом\")\n",
        "    keyboard.add(button_fandom)\n",
        "    return keyboard\n",
        "\n",
        "def create_fandom_keyboard():\n",
        "    keyboard = types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)\n",
        "    button_eo = types.KeyboardButton(\"🌹💌 Евгений Онегин\")\n",
        "    button_lotr = types.KeyboardButton(\"🧙✨ Властелин Колец\")\n",
        "    button_ip = types.KeyboardButton(\"👑⚔️ Игра престолов\")\n",
        "    button_da = types.KeyboardButton(\"🔥🐲 Dragon Age\")\n",
        "    button_core = types.KeyboardButton(\"🦹🏻❤️ Алые сердца Корё\")\n",
        "    keyboard.add(button_eo, button_lotr, button_ip, button_da, button_core)\n",
        "    return keyboard\n",
        "\n",
        "\n",
        "# @bot.message_handler(func=lambda message: message.text == \"Изобразить\")\n",
        "# def command_for_pic(message):\n",
        "#     bot.reply_to(message, reply_markup=create_picture_keyboard())\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text == \"Изобразить\")\n",
        "def handle_picture_request(message):\n",
        "    global context_q\n",
        "    if context_q:\n",
        "        last_answer = context_q[-1]['content']\n",
        "        if context_q[-1]['role'] == 'system':\n",
        "            pic_prompt = gemma_create_prompt(last_answer)\n",
        "        else:\n",
        "            pic_prompt = context_q[-2]['content'] if len(context_q) > 1 else \"\"\n",
        "    else:\n",
        "        pic_prompt = \"\"\n",
        "    try:\n",
        "        image = picture_generate(pic_prompt)\n",
        "        image.save('generated_image.jpg')\n",
        "        bot.send_photo(message.chat.id, open('generated_image.jpg', 'rb'))\n",
        "        bot.send_message(message.chat.id, \"Выберите фандом:\", reply_markup=create_keyboard())\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка генерации: {e}\")\n",
        "        bot.reply_to(message, \"Не удалось создать изображение 😔\")\n",
        "            # Создаем поток байтов\n",
        "            # buffer = BytesIO()\n",
        "            # image.save(buffer, format='JPEG')\n",
        "            # buffer.seek(0)\n",
        "\n",
        "           # Отправляем изображение как байты\n",
        "            #bot.send_photo(message.chat.id, buffer)\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text == \"📚 Выбрать фандом\")\n",
        "def choose_fandom(message):\n",
        "    bot.reply_to(message, \"Выбери фандом:\", reply_markup=create_fandom_keyboard())\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text in fandoms)\n",
        "def handle_fandom(message):\n",
        "    global context_q\n",
        "    global df\n",
        "    user_id = message.from_user.id\n",
        "    fandom = message.text\n",
        "\n",
        "    # Получаем промпт для выбранного фандома\n",
        "    prompt = get_fandom_prompt(df, fandom)\n",
        "\n",
        "    if dialog_check == 1:\n",
        "      answer, context_q = process_dialogue_step(prompt, context_q)\n",
        "    if answer is not None:\n",
        "        bot.reply_to(message, f\"{answer}\\nПродолжать?\", reply_markup=create_picture_keyboard())\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def answer_the_question(message):\n",
        "    global context_q\n",
        "    global dialog_check\n",
        "    user_message = message.text\n",
        "\n",
        "    # Проверка на команду завершения\n",
        "    if user_message.lower() in [\"стоп\", \"хватит\", \"закончим\"]:\n",
        "        bot.reply_to(message, \"Хорошо, давай закончим. Если захочешь ещё историй, просто напиши!\")\n",
        "        context_q.clear()  # Очищаем контекст\n",
        "        dialog_check = 0\n",
        "        return\n",
        "\n",
        "    if dialog_check == 0:\n",
        "        bot.reply_to(message, \"Привет! Я Элфо! Какую историю ты хочешь почитать?\", reply_markup=create_keyboard())\n",
        "        dialog_check = 1\n",
        "        return\n",
        "\n",
        "    if dialog_check == 1:\n",
        "      answer, context_q = process_dialogue_step(user_message, context_q)\n",
        "    if answer is not None:\n",
        "            bot.reply_to(message, answer, reply_markup=create_keyboard())\n",
        "            bot.reply_to(message, \"Что будет дальше?\")\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot.polling(none_stop=True)"
      ],
      "metadata": {
        "id": "2RfXU8AxHl1r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "yBukgTghbKN1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8xPadsybKQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rFyIHEHQbKTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8vOlZdybKWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_message_with_picture_keyboard(chat_id, text):\n",
        "    bot.send_message(chat_id=chat_id, text=text, reply_markup=create_picture_keyboard())"
      ],
      "metadata": {
        "id": "Bbb9n1B-XAwE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ekusfrCROOWi"
      },
      "outputs": [],
      "source": [
        "from telebot import types\n",
        "from collections import deque\n",
        "import logging\n",
        "import random\n",
        "\n",
        "\n",
        "# Инициализация контекста\n",
        "MAX_CONTEXT_LENGTH = 5\n",
        "user_contexts = {}\n",
        "dialog_check = 0\n",
        "\n",
        "# Создаем клавиатуру\n",
        "def create_keyboard():\n",
        "    keyboard = types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)\n",
        "    button_random = types.KeyboardButton(\"🎲 Рандомный сюжет от Элфо\")\n",
        "    button_fandom = types.KeyboardButton(\"📚 Выбрать фандом\")\n",
        "    button_continue = types.KeyboardButton(\"➡️ Продолжить историю\")\n",
        "    keyboard.add(button_random, button_fandom, button_continue)\n",
        "    return keyboard\n",
        "\n",
        "# Клавиатура для выбора фандома\n",
        "def create_fandom_keyboard():\n",
        "    keyboard = types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)\n",
        "    button_hp = types.KeyboardButton(\"🪄 Гарри Поттер\")\n",
        "    button_lotr = types.KeyboardButton(\"🧙 Властелин Колец\")\n",
        "    button_sw = types.KeyboardButton(\"⭐ Звёздные Войны\")\n",
        "    keyboard.add(button_hp, button_lotr, button_sw)\n",
        "    return keyboard\n",
        "\n",
        "# Функции для промптов\n",
        "def get_random_prompt():\n",
        "    prompts = [\n",
        "        \"Жил-был дракон, который любил чай...\",\n",
        "        \"Однажды в далёкой галактике...\",\n",
        "        \"В маленькой деревне жил волшебник, который боялся магии...\"\n",
        "    ]\n",
        "    return random.choice(prompts)\n",
        "\n",
        "def get_fandom_prompt(fandom):\n",
        "    prompts = {\n",
        "        \"🪄 Гарри Поттер\": \"Напиши историю о Гарри Поттере, который обнаружил новое заклинание...\",\n",
        "        \"🧙 Властелин Колец\": \"Напиши историю о Фродо, который нашёл новое кольцо...\",\n",
        "        \"⭐ Звёздные Войны\": \"Напиши историю о Люке Скайуокере, который встретил нового дроида...\"\n",
        "    }\n",
        "    return prompts.get(fandom, \"Фандом не найден.\")\n",
        "\n",
        "# Управление контекстом\n",
        "def get_user_context(user_id):\n",
        "    if user_id not in user_contexts:\n",
        "        user_contexts[user_id] = deque(maxlen=MAX_CONTEXT_LENGTH)\n",
        "    return user_contexts[user_id]\n",
        "\n",
        "# Обработка нажатий на кнопки\n",
        "@bot.message_handler(func=lambda message: message.text == \"🎲 Рандомный сюжет от Элфо\")\n",
        "def random_story(message):\n",
        "    prompt = get_random_prompt()\n",
        "    bot.reply_to(message, prompt)\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text == \"📚 Выбрать фандом\")\n",
        "def choose_fandom(message):\n",
        "    bot.reply_to(message, \"Выбери фандом:\", reply_markup=create_fandom_keyboard())\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text in [\"🪄 Гарри Поттер\", \"🧙 Властелин Колец\", \"⭐ Звёздные Войны\"])\n",
        "def handle_fandom(message):\n",
        "    user_id = message.from_user.id\n",
        "    fandom = message.text\n",
        "\n",
        "    # Получаем промпт для выбранного фандома\n",
        "    prompt = get_fandom_prompt(fandom)\n",
        "\n",
        "    # Отправляем запрос к модели\n",
        "    try:\n",
        "        answer = dialogue_model(prompt, list(get_user_context(user_id)))\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Ошибка в dialogue_model: {e}\")\n",
        "        bot.reply_to(message, \"Произошла ошибка. Попробуйте ещё раз.\")\n",
        "        return\n",
        "\n",
        "    if not answer:\n",
        "        logging.error(\"Пустой ответ от dialogue_model\")\n",
        "        bot.reply_to(message, \"Кажется, Элфо заснул... Попробуйте ещё раз.\")\n",
        "        return\n",
        "\n",
        "    # Отправляем ответ пользователю\n",
        "    bot.reply_to(message, answer)\n",
        "\n",
        "    # Обновляем контекст\n",
        "    context_q = get_user_context(user_id)\n",
        "    context_q.append({\"user\": prompt, \"assistant\": answer})\n",
        "\n",
        "    # Возвращаем основную клавиатуру\n",
        "    bot.reply_to(message, \"Что будет дальше?\", reply_markup=create_keyboard())\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text == \"➡️ Продолжить историю\")\n",
        "def continue_story(message):\n",
        "    user_id = message.from_user.id\n",
        "    context_q = get_user_context(user_id)\n",
        "    if context_q:\n",
        "        bot.reply_to(message, \"Продолжи историю:\")\n",
        "    else:\n",
        "        bot.reply_to(message, \"Сначала выбери сюжет или фандом!\", reply_markup=create_keyboard())\n",
        "\n",
        "# Основная логика\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def answer_the_question(message):\n",
        "    global dialog_check\n",
        "\n",
        "    user_id = message.from_user.id\n",
        "    context_q = get_user_context(user_id)\n",
        "\n",
        "    def process_dialogue_step(user_message, context):\n",
        "        try:\n",
        "            answer = dialogue_model(user_message, list(context))\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка в dialogue_model: {e}\")\n",
        "            bot.reply_to(message, \"Произошла ошибка. Попробуйте ещё раз.\")\n",
        "            return None, None\n",
        "\n",
        "        if not answer:\n",
        "            logging.error(\"Пустой ответ от dialogue_model\")\n",
        "            bot.reply_to(message, \"Кажется, Элфо заснул... Попробуйте ещё раз.\")\n",
        "            return None, None\n",
        "\n",
        "        bot.reply_to(message, answer)\n",
        "        context.append({\"user\": user_message, \"assistant\": answer})\n",
        "        logging.info(f\"Updated context: {context}\")\n",
        "\n",
        "        return answer, context\n",
        "\n",
        "    user_message = message.text\n",
        "\n",
        "    if user_message.lower() in [\"очистить\", \"стоп\", \"хватит\"]:\n",
        "        context_q.clear()\n",
        "        dialog_check = 0\n",
        "        bot.reply_to(message, \"Контекст очищен. Начнём с чистого листа!\", reply_markup=create_keyboard())\n",
        "        return\n",
        "\n",
        "    if dialog_check == 0:\n",
        "        bot.reply_to(message, \"Привет! Я Элфо! Какую историю ты хочешь почитать?\", reply_markup=create_keyboard())\n",
        "        dialog_check = 1\n",
        "        return\n",
        "\n",
        "    if dialog_check == 1:\n",
        "        answer, context_q = process_dialogue_step(user_message, context_q)\n",
        "\n",
        "        if answer is not None:\n",
        "            bot.reply_to(message, answer)\n",
        "            bot.reply_to(message, \"Что будет дальше?\", reply_markup=create_keyboard())\n",
        "        return\n",
        "\n",
        "# Запуск бота\n",
        "bot.polling()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Esgh27uL-DVZ"
      },
      "outputs": [],
      "source": [
        "bot.polling(none_stop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Icypsu-qpjQz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvA5qlM2pjTN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS67OPxlpjVe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbIe02EQpjYC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGlPLAzzpjaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me4HsKtPpjfE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRhCF8bcpjho"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWAKKmzVpjkA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr0nVuQXpjmc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBS4fc7fpjo5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WGfrcnApjrM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# # @bot.message_handler(commands=['start'])\n",
        "# # def greet_user(message):\n",
        "# #   bot.send_message(message.chat.id, \"\")\n",
        "\n",
        "# import logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# dialog_check = 0\n",
        "# context_q = []\n",
        "# question = \"\"\n",
        "# @bot.message_handler(func=lambda message: True)\n",
        "# def answer_the_question(message):\n",
        "\n",
        "#   global dialog_check\n",
        "#   global context_q\n",
        "#   global question\n",
        "\n",
        "#   if dialog_check == 0:\n",
        "#     bot.reply_to(message, \"Привет! Я Элфо! Какую историю, ты хочешь почитать?\")\n",
        "#     dialog_check = 1\n",
        "#     return\n",
        "\n",
        "#   if dialog_check == 1:\n",
        "#     user_message = message.text\n",
        "#     try:\n",
        "#       answer = dialogue_model(user_message, context_q)\n",
        "#     except Exception as e:\n",
        "#       logging.error(f\"Ошибка в dialogue_model: {e}\")\n",
        "#       bot.reply_to(message, \"Произошла ошибка. Попробуйте ещё раз.\")\n",
        "#       return\n",
        "\n",
        "\n",
        "#     bot.reply_to(message, answer)\n",
        "\n",
        "#     if not answer:\n",
        "#       logging.error(\"Пустой ответ от dialogue_model\")\n",
        "#       bot.reply_to(message, \"Кажется, Элфо заснул... Попробуйте ещё раз.\")\n",
        "#       return\n",
        "\n",
        "#     context_q = update_context(context_q, user_message, answer)\n",
        "\n",
        "#     logging.info(f\"Updated context: {context_q}\")\n",
        "#     dialog_check = 2\n",
        "#     return\n",
        "\n",
        "#   if dialog_check == 2:\n",
        "#     user_message = message.text\n",
        "#     answer = dialogue_model(user_message, context_q)\n",
        "#     bot.reply_to(message, answer)\n",
        "#     ## обновляем контекст\n",
        "#     context_q = update_context(context_q, user_message, answer)\n",
        "#     print(context_q)\n",
        "#     dialog_check = 0\n",
        "#     return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## вот тут все хорошо работало:\n",
        "\n",
        "# @bot.message_handler(func=lambda message: True)\n",
        "# def answer_the_question(message):\n",
        "#     global context_q\n",
        "#     global dialog_check\n",
        "\n",
        "#     def process_dialogue_step(user_message, context):\n",
        "#         try:\n",
        "#             answer = dialogue_model(user_message, list(context))  # Преобразуем deque в список\n",
        "#         except Exception as e:\n",
        "#             logging.error(f\"Ошибка в dialogue_model: {e}\")\n",
        "#             bot.reply_to(message, \"Произошла ошибка. Попробуйте ещё раз.\")\n",
        "#             return None, None\n",
        "\n",
        "#         if not answer:\n",
        "#             logging.error(\"Пустой ответ от dialogue_model\")\n",
        "#             bot.reply_to(message, \"Кажется, Элфо заснул... Попробуйте ещё раз.\")\n",
        "#             return None, None\n",
        "\n",
        "#         bot.reply_to(message, answer)\n",
        "#         context = update_context(context, user_message, answer)\n",
        "#         logging.info(f\"Updated context: {context}\")\n",
        "\n",
        "#         return answer, context\n",
        "\n",
        "#     user_message = message.text\n",
        "\n",
        "#     # Проверка на команду завершения\n",
        "#     if user_message.lower() in [\"стоп\", \"хватит\", \"закончим\"]:\n",
        "#         bot.reply_to(message, \"Хорошо, давай закончим. Если захочешь ещё историй, просто напиши!\")\n",
        "#         context_q.clear()  # Очищаем контекст\n",
        "#         return\n",
        "\n",
        "#     if dialog_check == 0:\n",
        "#         bot.reply_to(message, \"Привет! Я Элфо! Какую историю ты хочешь почитать?\")\n",
        "#         dialog_check = 1\n",
        "#         return\n",
        "\n",
        "#     # Обработка шага диалога\n",
        "#     if dialog_check == 1:\n",
        "#       answer, context_q = process_dialogue_step(user_message, context_q)\n",
        "\n",
        "\n",
        "#     if context_q:  # Если ответ успешно сгенерирован\n",
        "#         bot.reply_to(message, \"Что будет дальше?😜\")  # Подсказка для продолжения\n",
        "\n",
        "#     return"
      ],
      "metadata": {
        "id": "KnGH1C5YEwKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd9H5XZy/F5Q0vErF7sXX9"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}